{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Languages and language learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a part of an online statistics course on Udacity.com, I decided to work on a project where I could make use of the skills I learned. I chose to conduct a brief survey about people's knowledge of languages. In this document, I will show you how I collected the data, how I processed it, and some of the interesting results I obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The survey was created using the free online tool Google Forms. I shared it among other students taking part in the aforementioned course, namely on the course's Slack channel and its Udacity forum. Besides those, I posted a link to the survey on Reddit subreddits r/SampleSize and r/languagelearning, and I also shared it among some of my friends. For these reasons, the results will not represent the general population in some aspects, as these channels are mainly English speaking communities and some age groups are not adequately represented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting enough data, I had to ensure that all of it is in the desired format. Google Forms offers the option to download survey data in the form of a csv file, which is what I worked with. Here is a brief summary of the data. The original dataset contained the column 'email', which was removed from the dataset used for this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timestamp' 'combined_no' 'native_no' 'foreign_no' 'native1' 'native2'\n",
      " 'native3' 'native4' 'native5' 'foreign1' 'foreign1_lvl' 'foreign2'\n",
      " 'foreign2_lvl' 'foreign3' 'foreign3_lvl' 'foreign4' 'foreign4_lvl'\n",
      " 'foreign5' 'foreign5_lvl' 'foreign_other' 'age_first' 'hours_week'\n",
      " 'methods' 'eff_school' 'eff_course' 'eff_self' 'eff_textbook'\n",
      " 'eff_online' 'eff_native' 'eff_media' 'eff_travel' 'enj_school'\n",
      " 'enj_course' 'enj_self' 'enj_textbook' 'enj_online' 'enj_native'\n",
      " 'enj_media' 'enj_travel' 'study_cur' 'study_future' 'gender' 'age'\n",
      " 'country' 'education' 'employment']\n",
      "        native_no  foreign_no         age\n",
      "count  240.000000  240.000000  240.000000\n",
      "mean     1.200000    2.097917   23.387500\n",
      "std      0.450012    1.415617    8.620051\n",
      "min      1.000000    0.000000    0.000000\n",
      "25%      1.000000    1.000000   18.000000\n",
      "50%      1.000000    2.000000   22.000000\n",
      "75%      1.000000    3.000000   28.000000\n",
      "max      4.000000    9.000000   62.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(\"languages_data.csv\", 'r') as datafile:\n",
    "    data = pd.read_csv(datafile)\n",
    "\n",
    "# Print the list of columns in the DataFrame\n",
    "print(data.columns.values)\n",
    "\n",
    "# Print a brief summary of selected columns\n",
    "cols = ['native_no', 'foreign_no', 'age']\n",
    "print(data[cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in which we're most interested are `native_no` (number of native languages a repondent has listed), `foreign_no` (number of foreign languages) and each of the `nativeX` and `foreignX` columns that contain the names of the languages a given person speaks.\n",
    "\n",
    "If we run the code above, we can see that we have 240 responses in total (as the three columns above contain responses to questions that were obligatory). Some interesting observations we can make from this data is that everyone has at least one native language or that the respondents to this survey speak approximately 2 languages on average.\n",
    "\n",
    "It also seems that the highest number of native languages a person has is 4. We can look at the column containing the 4th native language to check this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "print(data['native4'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks that the column doesn't contain any values at all. Since having four native languages is relatively uncommon, we can assume that it was a typo and that the highest number of native languages is in fact 3 or less. Therefore, we can drop columns `native4` and `native5` so that we don't have to worry about them later. For the time being, we will leave the (most likely wrong) value of 4 as it is, as we will deal with similar irregularities later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "# make sure column 'native5' doesn't contain any values\n",
    "print(data['native5'].unique())\n",
    "\n",
    "# drop columns 'native4' and 'native5'\n",
    "data = data.drop(columns=['native4', 'native5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check each of the five columns that contain foreign languages, we can see that each contains at least one non-empty value. Therefore, we will keep all the columns intact.\n",
    "\n",
    "We can look at values in the native and foreign languages columns to get an idea about what languages are the most common. We will see that we get some languages listed more than once. The reasons for this, among others, are inconsistent capitalization, trailing spaces, typos etc. We will have to correct these values before we can perform any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "native1\n",
      "['English' 'Portuguese' 'Arabic' 'Polish' 'Italian' 'Hindi' 'German'\n",
      " 'Slovak' 'Estonian' 'Russian' 'Frisian' 'Spanish' 'Marathi' 'French'\n",
      " 'Catalan' 'Putonghua' 'Farsi' 'English ' 'Flemish' 'German ' 'Dutch'\n",
      " 'Turkish' 'PortuguĂŞs (Portuguese)' 'Bengali' 'Tamil' 'Cantonese'\n",
      " 'Finnish' 'Latvian' 'Czech' 'British English' 'vietnamese' 'Danish'\n",
      " 'Mandarin' 'english' 'Hungarian' 'romanian' 'Norway' 'Romanian' 'Greek'\n",
      " 'Hebrew' 'Swedish' 'english uk' 'portuguese' 'Gujrati'\n",
      " 'English (American)' 'slovak' 'Englidh' 'Malay' 'Indonesian' 'Ukrainian'\n",
      " 'Thai' 'Norwegian' 'arabic' 'polish' 'Malayalam' 'English, American'\n",
      " 'hindi' 'chinese' 'American English']\n",
      "native2\n",
      "['Yoruba' nan 'Dutch' 'Hindi' 'Assyrian' 'Spanish' 'Contonese' 'English'\n",
      " 'English ' 'Cebuano' 'Twi' 'French' 'Vietnamese' 'Russian' 'Limburgish'\n",
      " 'mandarin' 'Scots' 'Valencian' 'Mandarin' 'Swedish' 'Czech' 'portuguese'\n",
      " 'Croatian' 'Filipino' 'Bhojpuri' 'Tamil' 'Chinese, Cantonese' 'Sardinian'\n",
      " 'Memon' 'Chinese' 'Mandarin ']\n",
      "native3\n",
      "[nan 'Sanskrit'\n",
      " \"Spanish (I learnt when I was 9, so I'm fluent but not technically native)\"\n",
      " 'Russian' 'English ' 'German']\n",
      "foreign1\n",
      "['None' 'Spanish' 'English' 'English ' 'Turkish' 'Korean ' nan 'Japanese'\n",
      " 'German' 'French' 'German ' 'French ' 'Japanese ' 'Latin' 'Esperanto'\n",
      " 'Swedish' 'Spansih' 'Ger,am' 'french' 'Italian' 'Mandarin Chinese'\n",
      " 'English (C2/fluent?)' 'Korean' 'english' 'spanish'\n",
      " 'American Sign Language ' '0' 'Portuguese' 'Dutch' 'French B1' 'Spanish '\n",
      " 'Czech' 'Polski kurwa' 'Norwegian' 'Chinese (mandarin)' 'Cantonese'\n",
      " 'Mandarin' 'Chinese']\n",
      "foreign2\n",
      "[nan 'Spanish' 'Turkish' 'Lithuanian' 'Urdu' 'Italian' 'French' 'Russian'\n",
      " 'Korean' 'German' 'Chinese Mandarin' 'Japanese' 'Dutch' 'Arabic'\n",
      " 'Japonese ' 'Irish' 'Armenian ' 'Cantonese' 'Esperanto' 'Polish'\n",
      " 'Chinese' 'Finnish' 'Swedish' 'English' 'Danish' 'english' 'Norwegian'\n",
      " 'french' 'Latin' 'Portuguese ' 'Greek' 'Portuguese' 'korean' 'Japanese '\n",
      " 'French ' 'Spanish ' 'INGLIĹ\\xa0' 'Mandarin' 'Hindi' 'romania'\n",
      " 'Mandarin Chinese']\n",
      "foreign3\n",
      "[nan 'French' 'Russian' 'German' 'Spanish' 'Esperanto' 'Japanese' 'Hindi'\n",
      " 'Hawaiian' 'Chinese' 'Latin' 'German (Deutsch)' 'Greek' 'Mandarin'\n",
      " 'Arabic' 'Portuguese' 'Maori' 'Norwegian' 'Icelandic' 'hungarian'\n",
      " 'English' 'Finnish' 'Danish' 'Portugese' 'Swedish' 'Dutch' 'Italian'\n",
      " 'Tamil' 'Shanghai Dialect' 'Malay']\n",
      "foreign4\n",
      "[nan 'Latvian' 'German' 'Welsh' 'Afrikaans' 'Armenian' 'French' 'Czech'\n",
      " 'Finnish' 'Italian' 'Russian ' 'Russian' 'Telugu' 'Swedish' 'Japanese'\n",
      " 'german' 'Serbian' 'American Sign Language' 'Turkish' 'Norwegian'\n",
      " 'Ukrainian' 'Spanish' 'Latin' 'Portuguese']\n",
      "foreign5\n",
      "[nan 'Norwegian' 'Catalan' 'Vietnamese' 'Turkish' 'Russian' 'French'\n",
      " 'Portuguese' 'Korean' 'German' 'spanish' 'Danish' 'Italian']\n"
     ]
    }
   ],
   "source": [
    "# create list of names of the columns that contain native and foreign languages\n",
    "native_cols = ['native1', 'native2', 'native3']\n",
    "foreign_cols = ['foreign1', 'foreign2', 'foreign3', 'foreign4', 'foreign5']\n",
    "\n",
    "# print unique values in each column\n",
    "for col in native_cols + foreign_cols:\n",
    "    print(col)\n",
    "    print(data[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will deal with capitalization. The Pandas module makes it relatively easy to perform string operations on a Pandas Series without iterating over all of them, which would be very inefficient. However, we still have to iterate over columns, as string methods can't be applied to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "native1\n",
      "['English' 'Portuguese' 'Arabic' 'Polish' 'Italian' 'Hindi' 'German'\n",
      " 'Slovak' 'Estonian' 'Russian' 'Frisian' 'Spanish' 'Marathi' 'French'\n",
      " 'Catalan' 'Putonghua' 'Farsi' 'English ' 'Flemish' 'German ' 'Dutch'\n",
      " 'Turkish' 'Portuguăşs (Portuguese)' 'Bengali' 'Tamil' 'Cantonese'\n",
      " 'Finnish' 'Latvian' 'Czech' 'British English' 'Vietnamese' 'Danish'\n",
      " 'Mandarin' 'Hungarian' 'Romanian' 'Norway' 'Greek' 'Hebrew' 'Swedish'\n",
      " 'English Uk' 'Gujrati' 'English (American)' 'Englidh' 'Malay'\n",
      " 'Indonesian' 'Ukrainian' 'Thai' 'Norwegian' 'Malayalam'\n",
      " 'English, American' 'Chinese' 'American English']\n",
      "native2\n",
      "['Yoruba' nan 'Dutch' 'Hindi' 'Assyrian' 'Spanish' 'Contonese' 'English'\n",
      " 'English ' 'Cebuano' 'Twi' 'French' 'Vietnamese' 'Russian' 'Limburgish'\n",
      " 'Mandarin' 'Scots' 'Valencian' 'Swedish' 'Czech' 'Portuguese' 'Croatian'\n",
      " 'Filipino' 'Bhojpuri' 'Tamil' 'Chinese, Cantonese' 'Sardinian' 'Memon'\n",
      " 'Chinese' 'Mandarin ']\n",
      "native3\n",
      "[nan 'Sanskrit'\n",
      " \"Spanish (I Learnt When I Was 9, So I'M Fluent But Not Technically Native)\"\n",
      " 'Russian' 'English ' 'German']\n",
      "foreign1\n",
      "['None' 'Spanish' 'English' 'English ' 'Turkish' 'Korean ' nan 'Japanese'\n",
      " 'German' 'French' 'German ' 'French ' 'Japanese ' 'Latin' 'Esperanto'\n",
      " 'Swedish' 'Spansih' 'Ger,Am' 'Italian' 'Mandarin Chinese'\n",
      " 'English (C2/Fluent?)' 'Korean' 'American Sign Language ' '0'\n",
      " 'Portuguese' 'Dutch' 'French B1' 'Spanish ' 'Czech' 'Polski Kurwa'\n",
      " 'Norwegian' 'Chinese (Mandarin)' 'Cantonese' 'Mandarin' 'Chinese']\n",
      "foreign2\n",
      "[nan 'Spanish' 'Turkish' 'Lithuanian' 'Urdu' 'Italian' 'French' 'Russian'\n",
      " 'Korean' 'German' 'Chinese Mandarin' 'Japanese' 'Dutch' 'Arabic'\n",
      " 'Japonese ' 'Irish' 'Armenian ' 'Cantonese' 'Esperanto' 'Polish'\n",
      " 'Chinese' 'Finnish' 'Swedish' 'English' 'Danish' 'Norwegian' 'Latin'\n",
      " 'Portuguese ' 'Greek' 'Portuguese' 'Japanese ' 'French ' 'Spanish '\n",
      " 'Ingliĺ\\xa0' 'Mandarin' 'Hindi' 'Romania' 'Mandarin Chinese']\n",
      "foreign3\n",
      "[nan 'French' 'Russian' 'German' 'Spanish' 'Esperanto' 'Japanese' 'Hindi'\n",
      " 'Hawaiian' 'Chinese' 'Latin' 'German (Deutsch)' 'Greek' 'Mandarin'\n",
      " 'Arabic' 'Portuguese' 'Maori' 'Norwegian' 'Icelandic' 'Hungarian'\n",
      " 'English' 'Finnish' 'Danish' 'Portugese' 'Swedish' 'Dutch' 'Italian'\n",
      " 'Tamil' 'Shanghai Dialect' 'Malay']\n",
      "foreign4\n",
      "[nan 'Latvian' 'German' 'Welsh' 'Afrikaans' 'Armenian' 'French' 'Czech'\n",
      " 'Finnish' 'Italian' 'Russian ' 'Russian' 'Telugu' 'Swedish' 'Japanese'\n",
      " 'Serbian' 'American Sign Language' 'Turkish' 'Norwegian' 'Ukrainian'\n",
      " 'Spanish' 'Latin' 'Portuguese']\n",
      "foreign5\n",
      "[nan 'Norwegian' 'Catalan' 'Vietnamese' 'Turkish' 'Russian' 'French'\n",
      " 'Portuguese' 'Korean' 'German' 'Spanish' 'Danish' 'Italian']\n"
     ]
    }
   ],
   "source": [
    "for col in native_cols + foreign_cols:\n",
    "    data[col] = data[col].str.title()\n",
    "    print(col)\n",
    "    print(data[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already notice fewer unique names of languages. E.g., before, the column `native1` contained both `romanian` and `Romanian`. However, now there is a single value of `Romanian`.\n",
    "\n",
    "Nevertheless, the dataset still contains values that can't be dealt with programatically. We will need to replace values such as `Ger,am` with its correct equivalent. For this, we will create a dictionary of misspellings and then iterate over the values to see if they need to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "language_typos = {'None': np.nan, '0': np.nan,\n",
    "                  'English ': 'English', 'English (C2/Fluent?)': 'English', 'Ingliĺ\\xa0': 'English', 'Englidh': 'English',\n",
    "                  'English, American': 'English','American English': 'English', 'English (American)': 'English',\n",
    "                  'British English': 'English', 'English Uk': 'English',\n",
    "                  'Ger,Am': 'German', 'German ': 'German', 'German (Deutsch)': 'German',\n",
    "                  \"Spanish (I Learnt When I Was 9, So I'M Fluent But Not Technically Native)\": 'Spanish',\n",
    "                  'Spanish ': 'Spanish', 'Spansih': 'Spanish', 'French B1': 'French', 'French ': 'French',\n",
    "                  'Portuguese ': 'Portuguese', 'Portuguăşs (Portuguese)': 'Portuguese',\n",
    "                  'Japanese ': 'Japanese', 'Japonese ': 'Japanese', 'Chinese': 'Mandarin', 'Mandarin Chinese': 'Mandarin',\n",
    "                  'Chinese (Mandarin)': 'Mandarin', 'Mandarin ': 'Mandarin', 'Contonese': 'Cantonese',\n",
    "                  'Armenian ': 'Armenian', 'Norway': 'Norwegian',\n",
    "                  'Korean ': 'Korean', 'Polski Kurwa': 'Polish', 'Romania': 'Romanian', 'Russian ': 'Russian',\n",
    "                  'American Sign Language ': 'American Sign Language'                   \n",
    "                  }\n",
    "\n",
    "# check if a given cell value is in the language_typos dictionary, if so, replace it\n",
    "for col in native_cols + foreign_cols:\n",
    "    data[col] = data[col].fillna(value=np.nan)        # we want the empty value to be the same in the whole dataset\n",
    "    for i, row in data[[col]].iterrows():\n",
    "        cur_val = data.loc[i, col]\n",
    "        if cur_val in language_typos:\n",
    "            data.loc[i, col] = language_typos[cur_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, so now all the string values are what we want them to be. However, some people's answer to how many native or foreign languages they speak doesn't match the number of languages actually listed. For native languages, we will assume that the number of languages people wrote out is the correct number of their native languages. Therefore, we will correct the `native_no` column to match this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL DATA\n",
      "     native_no   native1   native2  native3\n",
      "20           1   English  Assyrian      NaN\n",
      "49           1     Dutch   English      NaN\n",
      "71           2   Catalan   English  Spanish\n",
      "101          1  Mandarin   English      NaN\n",
      "103          1   English    French  Russian\n",
      "119          2   English       NaN      NaN\n",
      "171          4     Hindi       NaN      NaN\n",
      "175          1   Spanish   English   German\n",
      "177          1      Thai   English      NaN\n",
      "191          2   Bengali       NaN      NaN\n",
      "\n",
      "CORRECTED DATA\n",
      "Empty DataFrame\n",
      "Columns: [native_no, native1, native2, native3]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "native_cols = ['native1', 'native2', 'native3']\n",
    "# count how many languages a person listed\n",
    "native_count = data[native_cols].count(axis='columns')\n",
    "\n",
    "# check if there is a difference between the native_no column and actual number of languages listed\n",
    "print(\"ORIGINAL DATA\")\n",
    "print(data.loc[data['native_no'] != native_count, ['native_no'] + native_cols])\n",
    "\n",
    "# change data in the native_no column to match the actual number of native languages\n",
    "data.loc[data['native_no'] != native_count, 'native_no'] = native_count\n",
    "\n",
    "# check again if there is a difference between native_no and the actual count\n",
    "print(\"\\nCORRECTED DATA\")\n",
    "print(data.loc[data['native_no'] != native_count, ['native_no'] + native_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do the same with the data for foreign languages. There is a difference, however: the table contains an additional column `foreign_other`, which contains language data for people who speak more than 5 foreign languages. This column can contain any number of languages separated by commas and we need to count them. To do this, we will create an extra column in the table called `foreign_other_count`. Obtaining the actual number of languages in each cell will not be hard thanks to Python's string methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 5]\n"
     ]
    }
   ],
   "source": [
    "# add all unique values in the column to a dictionary where\n",
    "# KEY is the cell value and VALUE is the number of languages\n",
    "foreign_other = data['foreign_other'].unique()\n",
    "foreign_other_dict = {}\n",
    "for item in foreign_other:\n",
    "    try:\n",
    "        foreign_other_dict[item] = len(item.replace(\" \", \"\").split(','))\n",
    "    except:\n",
    "        foreign_other_dict[item] = 0\n",
    "\n",
    "# now map the foreign_other column values to values in foreign_other_dict\n",
    "data['foreign_other_count'] = data['foreign_other'].map(foreign_other_dict)\n",
    "print(data['foreign_other_count'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have to take the `foreign_other_count` column into account when checking if the number of foreign languages is correct.\n",
    "\n",
    "The correction to the `foreign_no` column will be done the same way as for the `native_no` column: the value in the `foreign_no` column will be set to the actual number of languages listed, except the case that a person indicated that they speak more than 5 foreign languages but only listed 5 (that means that the `foreign_other` value is empty). In this case, we want to keep the original value of `foreign_no`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL DATA\n",
      "     foreign_no   foreign1  foreign2   foreign3 foreign4    foreign5\n",
      "10          4.0    Turkish   Russian    Spanish      NaN         NaN\n",
      "20          2.0        NaN       NaN        NaN      NaN         NaN\n",
      "30          3.0    English    French     German    Czech     Russian\n",
      "36          1.0    English     Dutch        NaN      NaN         NaN\n",
      "49          2.0    English    French    Spanish      NaN         NaN\n",
      "60          1.0     German   Spanish        NaN      NaN         NaN\n",
      "71          2.0     French  Japanese      Maori      NaN         NaN\n",
      "73          0.5    Spanish       NaN        NaN      NaN         NaN\n",
      "91          1.0  Esperanto    French    Spanish   German         NaN\n",
      "100         1.0        NaN       NaN        NaN      NaN         NaN\n",
      "102         2.0   Mandarin       NaN        NaN      NaN         NaN\n",
      "108         7.0    Spanish    French     German  Italian  Portuguese\n",
      "110         4.0    English    French  Hungarian   German     Spanish\n",
      "118         6.0    English    French    Spanish   German  Portuguese\n",
      "142         4.0    English  Japanese     German      NaN         NaN\n",
      "152         1.0     French    Arabic        NaN      NaN         NaN\n",
      "155         1.0    English    German        NaN      NaN         NaN\n",
      "157         1.0    Spanish    French        NaN      NaN         NaN\n",
      "162         1.0    English   Spanish        NaN  Russian         NaN\n",
      "179         4.0     Polish   English        NaN      NaN         NaN\n",
      "188         1.0        NaN       NaN        NaN      NaN         NaN\n",
      "190         9.0   Japanese  Mandarin    Swedish  Russian      French\n",
      "204         3.0    English   Spanish      Dutch    Latin         NaN\n",
      "215         1.0   Mandarin  Japanese        NaN      NaN         NaN\n",
      "223         4.0    English    French    Spanish      NaN         NaN\n",
      "227         1.0   Japanese   Spanish        NaN      NaN         NaN\n",
      "\n",
      "CORRECTED DATA\n",
      "     foreign_no  foreign1  foreign2 foreign3 foreign4    foreign5\n",
      "108         7.0   Spanish    French   German  Italian  Portuguese\n",
      "118         6.0   English    French  Spanish   German  Portuguese\n",
      "190         9.0  Japanese  Mandarin  Swedish  Russian      French\n"
     ]
    }
   ],
   "source": [
    "foreign_cols = foreign_cols = ['foreign1', 'foreign2', 'foreign3', 'foreign4', 'foreign5']\n",
    "# count how many foreign languages a person listed\n",
    "foreign_count = data[foreign_cols].count(axis='columns') + data['foreign_other_count']\n",
    "\n",
    "# check if there are any differences\n",
    "print(\"ORIGINAL DATA\")\n",
    "print(data.loc[data['foreign_no'] != foreign_count, ['foreign_no'] + foreign_cols])\n",
    "\n",
    "# set the 'foreign_no' value to actual number of languages listed\n",
    "# except for the case where 'foreign_no' is greater than 5\n",
    "data.loc[(data['foreign_no'] != foreign_count) & (data['foreign_no'] <= 5), 'foreign_no'] = foreign_count\n",
    "\n",
    "# check if there are any differences\n",
    "print(\"\\nCORRECTED DATA\")\n",
    "print(data.loc[data['foreign_no'] != foreign_count, ['foreign_no'] + foreign_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 3 rows left where the number of languages listed doesn't match the value in the `foreign_no` column. However, as the listing the remaining languages was optional, we want to keep the original value.\n",
    "\n",
    "Finally, we want to make changes to the `combined_no` column which should contain the sum of native and foreign languages for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL DATA\n",
      "           0\n",
      "count    240\n",
      "unique     2\n",
      "top     True\n",
      "freq     208\n",
      "\n",
      "CORRECTED DATA\n",
      "           0\n",
      "count    240\n",
      "unique     1\n",
      "top     True\n",
      "freq     240\n"
     ]
    }
   ],
   "source": [
    "# just for curiosity, let's look at how many combined_no values are wrong\n",
    "print(\"ORIGINAL DATA\")\n",
    "print(pd.DataFrame(data['native_no'] + data['foreign_no'] == data['combined_no']).describe())\n",
    "\n",
    "# set the 'combined_no' value to the sum of 'native_no' and 'foreign_no'\n",
    "data['combined_no'] = data['native_no'] + data['foreign_no']\n",
    "print(\"\\nCORRECTED DATA\")\n",
    "print(pd.DataFrame(data['native_no'] + data['foreign_no'] == data['combined_no']).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will want to make some minor changes to the `foreignX_lvl`, `eff_X` and `enj_X` columns. The `foreignX_lvl` (where X is a number 1-5) indicates the level of a person's ability in the language listed in column `foreignX`. Its values can be A1, A2, B1, B2, C1 or C2 (based on CEFR levels) where A1 is beginner and C2 is proficient. We want to convert these to numerical values so that later we can perform some analysis on this data.\n",
    "\n",
    "The columns `eff_X` and `enj_X` indicate how much a person thinks the learning method X is efficient or how much they enjoy it. The methods that can be substituted for X are: `school` (school classes), `course` (courses outside of school), `self` (self_study), `textbook` (learning from textbooks), `online` (online-learning tools such as videos, podcasts, mobile applications), `native` (conversation with native speakers), `media` (films, books, news etc.) and `travel` (traveling to the country where a given language is spoken). The values range from 1 to 5, where 1 is least efficient/enjoyable and 5 is most efficient/enjoyable. There is also a value \"Don't know\", which we want to substitute for NaN so that we can analyse the non-empty values later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEVEL STATS\n",
      "count    221.000000\n",
      "mean       4.294118\n",
      "std        1.516399\n",
      "min        1.000000\n",
      "25%        3.000000\n",
      "50%        5.000000\n",
      "75%        6.000000\n",
      "max        6.000000\n",
      "Name: foreign1_lvl, dtype: float64\n",
      "count    150.000000\n",
      "mean       2.900000\n",
      "std        1.379378\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        4.000000\n",
      "max        6.000000\n",
      "Name: foreign2_lvl, dtype: float64\n",
      "\n",
      "EFFICIENCY/ENJOYMENT STATS\n",
      "count    166.000000\n",
      "mean       4.349398\n",
      "std        1.043697\n",
      "min        1.000000\n",
      "25%        4.000000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max        5.000000\n",
      "Name: eff_native, dtype: float64\n",
      "count    135.000000\n",
      "mean       3.200000\n",
      "std        1.268446\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        4.000000\n",
      "max        5.000000\n",
      "Name: enj_course, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# map language levels to numbers 1-6\n",
    "level_cols = ['foreign1_lvl', 'foreign2_lvl', 'foreign3_lvl', 'foreign4_lvl', 'foreign5_lvl']\n",
    "level_to_number = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "for col in level_cols:\n",
    "    data[col] = data[col].map(level_to_number)\n",
    "# look at a summary of 2 of the columns\n",
    "print(\"LEVEL STATS\")\n",
    "for col in level_cols[:2]:\n",
    "    print(data[col].describe())\n",
    "    \n",
    "# map efficiency and enjoyment values to numbers 1-5 or NaN\n",
    "eff_cols = ['eff_school', 'eff_course', 'eff_self', 'eff_textbook',\n",
    "            'eff_online', 'eff_native', 'eff_media', 'eff_travel']\n",
    "enj_cols = ['enj_school', 'enj_course', 'enj_self', 'enj_textbook',\n",
    "            'enj_online', 'enj_native', 'enj_media', 'enj_travel']\n",
    "quality_to_number = {\"Don't know\": np.nan, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}\n",
    "for col in eff_cols + enj_cols:\n",
    "    data[col] = data[col].map(quality_to_number)\n",
    "# look at data for 'eff_native' and 'enj_course'\n",
    "print(\"\\nEFFICIENCY/ENJOYMENT STATS\")\n",
    "for col in ['eff_native', 'enj_course']:\n",
    "    print(data[col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Now that our data is finally in the form we want it to be, let's look at some statistics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the first three columns: `combined_no`, `native_no` and `foreign_no`. Now that we know that the data is correct, we can look at the mean, mode and median of each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN\n",
      "combined_no    3.350000\n",
      "native_no      1.216667\n",
      "foreign_no     2.133333\n",
      "dtype: float64\n",
      "\n",
      "MEDIAN\n",
      "combined_no    3.0\n",
      "native_no      1.0\n",
      "foreign_no     2.0\n",
      "dtype: float64\n",
      "\n",
      "MODE\n",
      "   combined_no  native_no  foreign_no\n",
      "0          3.0        1.0         1.0\n",
      "1          NaN        NaN         2.0\n"
     ]
    }
   ],
   "source": [
    "cols = ['combined_no', 'native_no', 'foreign_no']\n",
    "print(\"MEAN\")\n",
    "print(data[cols].mean())\n",
    "print(\"\\nMEDIAN\")\n",
    "print(data[cols].median())\n",
    "print(\"\\nMODE\")\n",
    "print(data[cols].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in the `foreign_no` column, two values are present the same number of times. That means that the same number of people speak 1 and 2 foreign languages.\n",
    "\n",
    "We can put all the values in a simple table so that we can come back to it later.\n",
    "\n",
    "|        | total number of languages | number of native languages | number of foreign languages |\n",
    "|--------|---------------------------|----------------------------|-----------------------------|\n",
    "| mean   |                  3.350000 |                   1.216667 |                    2.133333 |\n",
    "| median |                       3.0 |                        1.0 |                         2.0 |\n",
    "| mode   |                       3.0 |                        1.0 |                    1.0; 2.0 |\n",
    "\n",
    "However, these three values - mean, median and mode - don't tell us much on their own. It would be better to see how the values are distributed. We'll use one of the most popular Python graphic modules Matplotlib to show these values on a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "mean = data['combined_no'].mean()\n",
    "median = data['combined_no'].median()\n",
    "mode = data['combined_no'].mode()[0]\n",
    "max = data['combined_no'].max()\n",
    "min = data['combined_no'].min()\n",
    "\n",
    "# create histogram\n",
    "plt.hist(data['combined_no'], bins=int(max-min+1), range=(min,max+1),\n",
    "         align='left', color='paleturquoise', rwidth=0.9)\n",
    "plt.title('Total number of languages')\n",
    "plt.xticks(list(range(1,12)))\n",
    "plt.axvline(x=mean, color='navy')\n",
    "plt.axvline(x=median+0.04, color='green')\n",
    "plt.axvline(x=mode-0.04, color='darkorange')\n",
    "\n",
    "# add legend\n",
    "mean_patch = mpatches.Patch(color='navy', label='Mean')\n",
    "median_patch = mpatches.Patch(color='green', label='Median')\n",
    "mode_patch = mpatches.Patch(color='darkorange', label='Mode')\n",
    "plt.legend(handles=[mean_patch, median_patch, mode_patch],\n",
    "           bbox_to_anchor=(1,1), loc=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we can create similar visualizations for each of the 3 columns.\n",
    "\n",
    "<img src=\"./images/figure1.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
